#!/bin/env python

##Description
#=============
# This script is used to generate a filtered tab delimited structural variant (SV) 
# report from VCF output generated by Manta and/or Pindel. 
# The NGS data is generated through the Molecular Diagnostics Information Management System, 
# a web application hosting an NGS pipeline for SNV, CNV and SV calling 
# - developed by the bioinformatics team at 
# the Centre of Molecular Pathology in Sutton, UK. 

#Author: Sabri Jamal
#Date: 03/05/2020
#Version: v1.0

import vcf
import sys
import getopt
import numpy as np
import pysam
import sys
import re

##write script usage
def write_script_usage():
    script = "sv_vcf2report.py" #Name of script

    #Create report for both Manta and Pindel output
    print("\n***USAGE; Using all inputs creating report for both Pindel and Manta: \n")
    print("{script} --manta_vcf <manta somatic SV VCF file> \n --pindel_vcf <pindel somatic SV VCF file> \n --output_file <full path for output file a suffix will be added for the small indel and SV report separately> \n --bam <path to bam file> \n --annotSV_file <SV annotation file (AnnotSV)> \n --bed_interval_file <bed file as picard style interval list> \n --nr_bases2preview <number of REF/ALT bases to preview in SV default [20]> \n --small_indel_vcf <path to manta candidate small indel VCF> \n --indel_allele_frac_filter <small indel allelic fraction filter default [0.05]> \n --BND_pair_read_filter <SV type pair read filter; BND default [0]> \n --BND_split_read_filter <SV type split read filter; BND default [0]> \n --INV_pair_read_filter <SV type; INV filter for pair read default [0]> \n --INV_split_read_filter <SV type; INV filter for split read default [0]> \n --DUP_pair_read_filter <SV type; DUP filter for pair read default [0]> \n --DUP_split_read_filter <SV type; DUP filter for split read default [0]> \n --INS_pair_read_filter <SV type; INS filter for pair read default [0]> \n --INS_split_read_filter <SV type; INS filter for split read default [0]> \n --DEL_pair_read_filter <SV type; DEL filter for pair read default [0]> \n --DEL_split_read_filter <SV type; DEL filter for split read default [0]> \n --inv_PO_read_filter <SV type; INV RR (pair orientation) read support filter default [8] \n --fraction_SR_support_alt <fraction of support reads supporting ALT allele [0.05] Only Activated for Inversions and Insertions>\n".format(script=script))

    print("#NOTE! PR and SR filters can be set false (case insensitive) which will allow for dependancy on only one or the other type of read support. e.g. if PR for inversions is set to false the only the SR filter will be relied on for passing the variant\n")

   #Create report just for Manta
    print("***USAGE; Creating report for Manta: \n")
    print("{script} --manta_vcf <manta somatic SV VCF file> \n --output_file <full path for output file a suffix will be added for the small indel and SV report separately> \n --bam <path to bam file> \n --annotSV_file <SV annotation file (AnnotSV)> \n --bed_interval_file <bed file as picard style interval list> \n --nr_bases2preview <number of REF/ALT bases to preview in SV default [20]> \n --small_indel_vcf <path to manta candidate small indel VCF> \n --indel_allele_frac_filter <small indel allelic fraction filter default [0.05]> \n --BND_pair_read_filter <SV type pair read filter; BND default [0]> \n --BND_split_read_filter <SV type split read filter; BND default [0]> \n --INV_pair_read_filter <SV type; INV filter for pair read default [0]> \n --INV_split_read_filter <SV type; INV filter for split read default [0]> \n --DUP_pair_read_filter <SV type; DUP filter for pair read default [0]> \n --DUP_split_read_filter <SV type; DUP filter for split read default [0]> \n --INS_pair_read_filter <SV type; INS filter for pair read default [0]> \n --INS_split_read_filter <SV type; INS filter for split read default [0]> \n --DEL_pair_read_filter <SV type; DEL filter for pair read default [0]> \n --DEL_split_read_filter <SV type; DEL filter for split read default [0]> \n --inv_PO_read_filter <SV type; INV RR (pair orientation) read support filter default [8] \n --fraction_SR_support_alt <fraction of support reads supporting ALT allele [0.05] Only Activated for Inversions and Insertions>\n".format(script=script))

   #Create report just for Pindel
    print("***USAGE; Creating report for Pindel: \n")
    print("{script} --pindel_vcf <pindel somatic SV VCF file> \n --output_file <full path for output file a suffix will be added for the small indel and SV report separately> \n --nr_bases2preview <number of REF/ALT bases to preview in SV default [20]> \n".format(script=script))

def SV_vcf2dict_PINDEL(vcf_file, nr_bases2preview=20, annotSV_file=None, bed_interval_file=None):

    #Read and store SV annotations as dict and gene names as list
    #(both functions work but are hashed out to not use input)
    #bed_gene_list = bed2gene_list(bed_interval_file)
    #annotSV_dict = annotSV2dict(annotSV_file)

    #Convert SV vcf to dict
    sv_vcf_dict = consume_general_pindel(vcf_file, nr_bases2preview)

    #####################
    ## SET AS INACTIVE ##
    #####################
    ##Merge AnnotSV data (Not activated due to special case for AnnotSV and pindel output)
    # Pindel output will have to be treated the same way as bnd and insertions
    #i.e. start=start and end=start + 1
    #sv_vcf_dict = join_annotSV(sv_vcf_dict, annotSV_dict)

    return(sv_vcf_dict)

def consume_general_pindel(vcf_file, nr_bases2preview):
    ##Instantiate variables
    sv_vcf_dict = {}
    v_line2list = []

    #SV labels
    tandem_dup = "DUP:TANDEM"

    #Instantiate header values
    chrom = None
    start = None
    end = None
    svtype = None
    ref = None
    alt = None
    gene = None
    svformat = None
    sample_germline_format = None
    sample_tumour_format = None
    location = None
    NM = None
    ACMG = None
    AnnotSV_ID = None
    AnnotSV_ranking = None
    SV_length = None

    #read vcf to pyvcf obj
    my_vcf = vcf.Reader(open(vcf_file))

    count = 0
    for record in my_vcf:
        count += 1 #line count
        v_line2list = [] #reset

        chrom = record.CHROM
        start = record.POS
        end = record.sv_end
        svtype = record.INFO["SVTYPE"]
        ref = record.REF[0:nr_bases2preview]
        alt = [ str(alt_seq)[0:nr_bases2preview] for alt_seq in record.ALT ]
        alt = str(alt).replace("[","").replace("]","").replace("'", "")
        gene = None
        svformat = record.FORMAT
        format_ad = str(record.samples[0].data.AD).replace("[","").replace("]","")
        sample_tumour_format = "{GT}:{AD}".format(GT=record.samples[0].data.GT, AD=format_ad)
        location = None
        NM = None
        ACMG = None

        #Change label to much legacy label from annotator
        if(svtype == tandem_dup):
            svtype = svtype.replace(":TANDEM", "")

        AnnotSV_ID = "{c}_{s}_{e}_{sv}".format(c=chrom.replace("chr", ""), s=start, e=end, sv=svtype)
        svtype = record.INFO["SVTYPE"] #Reset using full label

        AnnotSV_ranking = None

        #SV is translocation, length cannot be established. NOTE! only first ALT read checked
        #(Needs more work to become fully generalised will need to perform list comprehension)
        if("chr" in str(record.ALT[0]).lower()):
            SV_length = "Suspected translocation"
        else:
            SV_length = abs(end - start)

        v_line2list = [chrom, start, end, svtype, ref, alt, gene, svformat, sample_germline_format, sample_tumour_format, location, NM, ACMG, AnnotSV_ID, AnnotSV_ranking, SV_length]

        if(count not in sv_vcf_dict):
            sv_vcf_dict[count] = v_line2list
        else:
            print("ERROR: Dictionary id must be unique, key already exists")


    return(sv_vcf_dict)

def SV_vcf2dict_MANTA(vcf_file, small_indel_vc, bam_file, annotSV_file, bed_interval_file, nr_bases2preview=20, allelic_fraction_filter=0.05, bnd_PR_filter=0, bnd_SR_filter=0, inv_PR_filter=0, inv_SR_filter=0, dup_PR_filter=0, dup_SR_filter=0, ins_PR_filter=0, ins_SR_filter=0, del_PR_filter=0, del_SR_filter=0, inv_PO_filter=8, fraction_SR_support_filter=0.05):

    ##Blacklisted BND genes
    blacklist_bnd_genes_dict = {"LINC00486": "Blacklist"}

    #Set split read dependancy only if PR filter set to false
    if(str(bnd_PR_filter).lower() == "false"):
        bnd_PR_filter = float('inf')
    if(str(inv_PR_filter).lower() == "false"):
        inv_PR_filter = float('inf')
    if(str(dup_PR_filter).lower() == "false"):
        dup_PR_filter = float('inf')
    if(str(ins_PR_filter).lower() == "false"):
        ins_PR_filter = float('inf')
    if(str(del_PR_filter).lower() == "false"):
        del_PR_filter = float('inf')

    #Set pair read dependancy only if SR filter set to false
    if(str(bnd_SR_filter).lower() == "false"):
        bnd_SR_filter = float('inf')
    if(str(inv_SR_filter).lower() == "false"):
        inv_SR_filter = float('inf')
    if(str(dup_SR_filter).lower() == "false"):
        dup_SR_filter = float('inf')
    if(str(ins_SR_filter).lower() == "false"):
        ins_SR_filter = float('inf')
    if(str(del_SR_filter).lower() == "false"):
        del_SR_filter = float('inf')

    ##Instantiate variables
    sv_vcf_dict = {}
    small_indel_vcf_dict = {}
    v_line2list = []
    nr_bases2preview = int(nr_bases2preview)
    af_filter = float(allelic_fraction_filter)

    #Read and store SV annotations as dict and gene names as list
    bed_gene_list = bed2gene_list(bed_interval_file)
    annotSV_dict = annotSV2dict(annotSV_file)

    #Parse BND translocations (count needs to be set to 0 for first function run)
    sv_vcf_dict, bnd_dict = consume_of_type_bnd(vcf_file, sv_vcf_dict, annotSV_dict, bed_gene_list, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter)
    sv_vcf_dict = find_full_event(sv_vcf_dict, bnd_dict)

    #Parse INV inversions
    sv_vcf_dict, inv_dict = consume_of_type_general(vcf_file, sv_vcf_dict, nr_bases2preview, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter, fraction_SR_support_filter)
    sv_vcf_dict = find_full_event(sv_vcf_dict, inv_dict)

    #Manta small indel calls
    small_indel_vcf_dict = extract_manta_small_indel_calls(small_indel_vc, bam_file, nr_bases2preview, af_filter)

    ##Merge AnnotSV data (currently only ranking)
    sv_vcf_dict = join_annotSV(sv_vcf_dict, annotSV_dict)

    # Apply filters
    #================
    #Exclude variants due to be filtered from final output
    sv_vcf_dict = exclude_filtered_var_from_dict(sv_vcf_dict)
    sv_vcf_dict = filter_inv_on_pair_orientation(sv_vcf_dict, inv_dict, bam_file, inv_PO_filter)
    sv_vcf_dict = filter_blacklisted_bnds(sv_vcf_dict, blacklist_bnd_genes_dict)

    result = [sv_vcf_dict, small_indel_vcf_dict]

    return(result)

def extract_manta_small_indel_calls(small_indel_vc, bam_file, nr_bases2preview, allelic_fraction_filter):

    ##Instantiate variables
    small_indel_vcf_dict = {}
    small_indel_vcf_dict_filtered = {}
    v_line2list = []
    v_line2list_filtered = []
    af_filter = allelic_fraction_filter

    #Variables to be outputted to report
    chrom = None
    start = None
    end = None
    indel_type = None
    ref = None
    alt = None
    gene = None
    sv_format = "DP:AD:AF"
    sample_germline_format = None
    sample_tumour_format = None
    location = None
    NM = None
    ACMG = None
    AnnotSV_ID = None
    AnnotSV_ranking = None
    indel_length = None

    #Indel labels
    deletion = "DEL"
    insertion = "INS"
    del_insertion = "DELINS"

    #Read vcf to pyvcf obj
    my_vcf = vcf.Reader(open(small_indel_vc))


    # Parse VCF records
    #===================
    line_count = 0
    count_indel = 0
    count_indel_filtered = 0
    for record in my_vcf:
        line_count += 1 #line count
        v_line2list = [] #reset
        v_line2list_filtered = [] #reset
        filter_indel = False
        indel_unique_id = ""

        chrom = record.CHROM
        start = record.POS

        # Check if DEL or INS and fetch length
        #======================================
        indel_length_list = []
        for alt_item in record.ALT:
            alt_item = str(alt_item)
            if( len(record.REF) > len(alt_item) ):
                indel_type = deletion
                indel_length_list.append( len(record.REF) - len(alt_item) )
            elif( len(record.REF) < len(alt_item) ):
                indel_type = insertion
                indel_length_list.append( len(alt_item) - len(record.REF) )
            elif( len(record.REF) == len(alt_item) ):
                indel_type = del_insertion
                indel_length_list.append( len(record.REF) )

        # Calculate which locus indel ends
        #==================================
        end_list = []
        for alt_length in indel_length_list:
            end_list.append(start + alt_length)

        end = str(end_list).replace("[","").replace("]","").replace("'", "").replace(" ", "")
        ref = record.REF[0:nr_bases2preview]
        alt = [ str(alt_seq)[0:nr_bases2preview] for alt_seq in record.ALT ]
        alt = str(alt).replace("[","").replace("]","").replace("'", "")
        indel_length = str(indel_length_list).replace("[","").replace("]","").replace("'", "").replace(" ", "")

        # Collect read information from vcf (AD) and BAM (DP)
        #=====================================================
        read_info_dict = collect_read_information_from_smallindel_event(record, end_list)
        DP_list = fetch_coverage(bam_file, chrom, start, end_list, indel_type)

        #NOTE! Does not support multi allelic calling at the moment.
        AF_germline_list = []
        AF_tumour_list = []
        AD_tumor = int(read_info_dict['TTIR'])
        AD_germline = int(read_info_dict['GTIR'])
        for DP_item in DP_list:
            if(DP_item == 0):
                AF_germline_list.append(0)
                AF_tumour_list.append(0)
            else:
                AF_germline_list.append( AD_germline/DP_item )
                AF_tumour_list.append( np.around(np.float(AD_tumor/DP_item), decimals=3 ))

        DP = str(DP_list).replace("[","").replace("]","").replace("'", "").replace(" ", "")
        AF_germline = "0"
        AF_tumour = str(AF_tumour_list).replace("[","").replace("]","").replace("'", "").replace(" ", "")
        #AF_germline = str(AF_germline_list).replace("]","").replace("'", "").replace(" ", "")

        #Leave estimating germline AF and set to None for now
        #sample_germline_format = "{DP}:{AD}:{AF}".format(DP=0, AD=0, AF=AF_germline)
        sample_germline_format = None
        sample_tumour_format = "{DP}:{AD}:{AF}".format(DP=DP, AD=AD_tumor, AF=AF_tumour)

        AnnotSV_ID = "{c}_{s}_{e}_{indel}".format(c=chrom.replace("chr", ""), s=start, e=end, indel=indel_type)

        #Construct dict item
        v_line2list = [chrom, start, end, indel_type, ref, alt, gene, sv_format, sample_germline_format, sample_tumour_format, location, NM, ACMG, AnnotSV_ID, AnnotSV_ranking, indel_length]
        indel_unique_id = "{c}:{s}:{e}:{ref}:{alt}".format(c=chrom, s=start, e=end, ref=ref, alt=alt)

        # Apply AF filter
        #=================
        for AF in AF_tumour_list:
            if( AF <= af_filter ):
                filter_indel = True
                count_indel_filtered += 1 #Artefact code previously the unique ID for dict
            else:
                filter_indel = False

                if(indel_unique_id not in small_indel_vcf_dict_filtered):
                    small_indel_vcf_dict_filtered[indel_unique_id] = v_line2list
                else:
                    print("ERROR: Key already exists. Dictionary id {count_indel_filtered} must be unique for indel filter ".format(count_indel_filtered=count_indel_filtered))

        # Store non filter var
        #=====================
        if(not filter_indel):
            count_indel += 1 #Artefact code previously the unique ID for dict
            if(indel_unique_id not in small_indel_vcf_dict):
                small_indel_vcf_dict[indel_unique_id] = v_line2list
            else:
                print("ERROR: Key already exists. Dictionary id {count_indel} must be unique for indels".format(count_indel=count_indel))

    return(small_indel_vcf_dict)

def consume_of_type_general(vcf_file, sv_vcf_dict, nr_bases2preview, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter, fraction_SR_support_filter):

    #Instantiate variables
    sample_germline_format = ""
    sample_tumour_format = ""
    inv_dict = {}

    #Variables to be outputted to report
    chrom = None
    start = None
    end = None
    sv_type = None
    ref = None
    alt = None
    gene = None
    sv_format = None
    sample_germline_format = None
    sample_tumour_format = None
    location = None
    NM = None
    ACMG = None
    AnnotSV_ID = None #For simplicity sake only first looped SV but will lead to loss of information
    AnnotSV_ranking = None
    SV_length = None

    #SV labels Manta
    breakend = "BND"
    inversion = "INV"
    insertion = "INS"
    deletion = "DEL"
    tandem_duplication = "DUP"

    #Read vcf to pyvcf obj
    my_vcf = vcf.Reader(open(vcf_file))

    count = 0
    for record in my_vcf:
        count += 1 #line count
        v_line2list = [] #reset
        sv_type = record.INFO["SVTYPE"]

        #Handle BNDs as special case i.e. Skip here. Check inversions for RR pair oriented read support
        if(sv_type == breakend):
            continue #skip all non BNDs
        else:
            sv_id = record.ID

            #Store for later parsing to join inversion events
            if( sv_type == inversion ):
                inv_dict[sv_id] = record

            chrom = record.CHROM
            start = record.POS
            end = record.sv_end
            ref = record.REF[0:nr_bases2preview]
            alt = [ str(alt_seq)[0:nr_bases2preview] for alt_seq in record.ALT ]
            alt = str(alt).replace("[","").replace("]","").replace("'", "")
            sv_format = record.FORMAT

            ## Check if read support filters passed
            #======================================
            keep_variant_read_support_filter = check_filter_variant(record, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter)

            ## Collect SV read information
            #==============================
            read_info_dict, keep_variant_frac_SR_support = collect_read_information_from_event(record, fraction_SR_support_filter)

            ## Determine if variant to be filtered due to fraction SR support and raw SR and PR counts
            #==========================================================================================
            if(keep_variant_read_support_filter and keep_variant_frac_SR_support):
                keep_variant = True
            else:
                keep_variant = False

            if( read_info_dict['TSR'] != ""):
                sample_tumour_format = "{PR};{SR}".format(PR=read_info_dict['TPR'], SR=read_info_dict['TSR'])
            else:
                sample_tumour_format = "{PR}".format(PR=read_info_dict['TPR'])

            if( len(record.samples) > 1):
                if( read_info_dict['GSR'] != ""):
                    sample_germline_format = "{PR};{SR}".format(PR=read_info_dict['GPR'],SR=read_info_dict['GSR'])
                else:
                    sample_germline_format = "{PR}".format(PR=read_info_dict['GPR'])
            else:
                sample_germline_format = None

            AnnotSV_ID = "{c}_{s}_{e}_{sv}".format(c=chrom.replace("chr", ""), s=start, e=end, sv=sv_type)

            if(sv_type == insertion):
                try:
                    SV_length = str(record.INFO['SVLEN']).replace("[","").replace("]","").replace("'", "")
                except KeyError:
                    #Insertion could not be assembled, report left and right end of insertion and overwrite alt
                    alt_left = [ str(alt_left_seq)[0:nr_bases2preview] for alt_left_seq in record.INFO['LEFT_SVINSSEQ'] ]
                    alt_left = str(alt_left).replace("[","").replace("]","").replace("'", "")
                    alt_right = [ str(alt_right_seq)[0:nr_bases2preview] for alt_right_seq in record.INFO['RIGHT_SVINSSEQ'] ]
                    alt_right = str(alt_right).replace("[","").replace("]","").replace("'", "")
                    alt = "(LEFT_INS_SEQ: {left});(RIGHT_INS_SEQ: {right})".format(left=alt_left, right=alt_right)
                    SV_length = "Unknown"
            else:
                SV_length = str(record.INFO['SVLEN']).replace("[","").replace("]","").replace("'", "")

            v_line2list = [chrom, start, end, sv_type, ref, alt, gene, sv_format, sample_germline_format, sample_tumour_format, location, NM, ACMG, AnnotSV_ID, AnnotSV_ranking, SV_length, keep_variant]

            if(sv_id not in sv_vcf_dict):
                sv_vcf_dict[sv_id] = v_line2list
            else:
                print("ERROR: Key already exists. Dictionary id {sv_id} must be unique for SV of type general".format(sv_id=sv_id))

    return(sv_vcf_dict, inv_dict)

def consume_of_type_bnd(vcf_file, sv_vcf_dict, annotSV_dict, bed_gene_list, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter):

    #Read vcf to pyvcf obj
    my_vcf = vcf.Reader(open(vcf_file))

    #Variables to be outputted to report
    chrom = None
    start = None
    end = None
    sv_type = None
    ref = None
    alt = None
    gene = None
    sv_format = None
    sample_germline_format = None
    sample_tumour_format = None
    location = None
    NM = None
    ACMG = None
    AnnotSV_ID = None #For simplicity sake only first looped SV but will lead to loss of information
    AnnotSV_ranking = None
    SV_length = None

    #SV labels Manta
    breakend = "BND"
    inversion = "INV"
    insertion = "INS"
    deletion = "DEL"
    tandem_duplication = "DUP"

    #Instantiate variables
    count = 0
    bnd_dict_on_panel = {}
    all_bnd_dict = {}


    ## Prepare ONLY BNDs in PANEL for later parsing
    #===========================
    for record in my_vcf:
        count += 1 #line count
        v_line2list = [] #reset
        software = "Manta" #Fetch from metadata for future proof
        mate_id = None
        gene = None
        sv_type = record.INFO["SVTYPE"]

        if(sv_type == breakend):
            #1bp SVs e.g. in breakends and insertions in annotSV are reported over 2 loci instead of being the same
            start = record.POS
            end = int(start) + 1
            key = "{chrom}:{start}:{end}:{sv_type}".format(chrom=record.CHROM.replace("chr", ""), start=start, end=end, sv_type=sv_type)

            #Fetch gene name from AnnotSV
            try:
                bnd_gene = annotSV_dict[key]['Gene name']
            except KeyError:
                bnd_gene = None
                print("UNEXPECTED EVENT OCCURED IN BNDs: No record located for key {key} in AnnotSV".format(key=key))

            #Skip if breakend doesn't span gene in panel (if the SV is on the panel the mate will cover a gene)
            if(bnd_gene not in bed_gene_list):
                try:
                    all_bnd_dict[record.ID] = [record, bnd_gene] #stores all bnds
                    continue
                except KeyError:
                    print("DEBUG UNEXPECTED EVENT OCCURED IN BNDs: BND does not have mate for SV {sv_id}".format(sv_id=sv_id))
                    mate_id = None

                continue
            else:
                try:
                    mate_id = record.INFO['MATEID'] #Try to initalise if no mate id BND is not a tranlocation (well at least with a known mate)
                    bnd_dict_on_panel[record.ID] = [record, bnd_gene]
                    all_bnd_dict[record.ID] = [record, bnd_gene]
                    continue #skip all non BNDs
                except KeyError:
                    print("DEBUG UNEXPECTED EVENT OCCURED IN BNDs: BND does not have mate for SV {sv_id}".format(sv_id=sv_id))
                    mate_id = None

    ## Parse through break ends matching pairs
    #==========================================
    all_bnd_dict_copy = all_bnd_dict.copy()
    sv_ids_parsed = []
    dict_count = 0
    for sv_id, value_list in bnd_dict_on_panel.items():
        record = value_list[0]
        gene = value_list[1]
        location = gene
        bnd_gene_partner_list = []

        #Check if sv_id has been parsed
        if(sv_id not in sv_ids_parsed):
            sv_ids_parsed.append(sv_id)
            dict_count += 1
        else:
            #sv_id has been found either as mate or as original entry
            continue

        #Mate related variables
        mate_info_dict = {}
        mate_format_list = []
        mate_id_list = record.INFO['MATEID'] #mates are returned as list, loop
        mate_id = None

        #Non mate dependant records (AnnotSV_ID is border line)
        chrom = record.CHROM
        start = record.POS
        end = start #BND start=stop
        alt = ""
        sv_format = "{form}".format(form=record.FORMAT)
        sv_type = record.INFO["SVTYPE"]
        ref = record.REF
        AnnotSV_ID = "{c}_{s}_{e}_{sv}".format(c=chrom.replace("chr", ""), s=start, e=end, sv=sv_type)
        SV_length = "1" #BND lengths always 1

        ## Check if read support filters passed
        #=======================================
        keep_variant_read_support_filter = check_filter_variant(record, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter)

        ## Collect ALT information from original entry (NOTE! record.ALT stored as list)
        #==========================================================================
        for alt_item in record.ALT:
            if( len(record.ALT) > 1 ):
                print("DEBUG UNEXPECTED EVENT OCCURED IN BNDs: while extracting ALT for SV id {sv_id}. More than one ALT reported for event".format(sv_id=sv_id))
            else:
                if( alt == ""):
                    alt_item = re.search("\w+:\d+", str(alt_item)).group()
                    alt = "(BND1: {alt_item})".format(alt_item=alt_item)
                else:
                    alt = "{alt};(BND1: {alt_item})".format(alt=alt, alt_item=alt_item)


        ## Collect SV read information for orignal entry
        #================================================
        read_info_dict, keep_variant_frac_SR_support = collect_read_information_from_event(record)

        if( read_info_dict['TSR'] != "" ):
            sample_tumour_format = "(BND1: {PR};{SR})".format(PR=read_info_dict['TPR'], SR=read_info_dict['TSR'])
        else:
            sample_tumour_format = "(BND1: {PR})".format(PR=read_info_dict['TPR'], SR=read_info_dict['TSR'])

        if( len(record.samples) > 1):
            if( read_info_dict['GSR'] != ""):
                sample_germline_format = "(BND1: {PR};{SR})".format(PR=read_info_dict['GPR'],SR=read_info_dict['GSR'])
            else:
                sample_germline_format = "(BND1: {PR})".format(PR=read_info_dict['GPR'])
        else:
            sample_germline_format = None

        ## Determine if variant to be filtered frac SR support filter no active for BNDs, boolean will always be true
        #============================================================================================================
        if(keep_variant_read_support_filter and keep_variant_frac_SR_support):
            keep_variant = True
        else:
            keep_variant = False

        # EXTRACT INFO FROM MATES
        #=========================
        break_end_count = 1
        mate_alts = ""
        mate_count = 0
        for mate in mate_id_list:
            mate_count += 1

            #Check if mate_id has been parsed
            if(mate not in sv_ids_parsed):
                sv_ids_parsed.append(mate)
                del all_bnd_dict_copy[mate]
                break_end_count += 1
            else:
                #sv_id has been found either as mate or as original entry
                continue

            ##Fetch mate vcf record and gene name
            mate_record = all_bnd_dict[mate][0]
            mate_bnd_gene = all_bnd_dict[mate][1]
            bnd_gene_partner_list.append(mate_bnd_gene)

            #Write gene fusion/translocation partners
            if( mate_count == len(mate_id_list) ):
                for bnd_partner_gene in bnd_gene_partner_list:
                    location = "{location}-{new_gene}".format(location=location, new_gene=bnd_partner_gene)

            # Collect ALT from mates
            #========================
            for alt_item in mate_record.ALT:
                if( len(mate_record.ALT) > 1 ):
                    print("DEBUG UNEXPECTED EVENT OCCURED IN BNDs: while extracting MATE ALT for MATE SV id {sv_id}. More than one ALT reported for event".format(sv_id=sv_id))
                else:
                    if( mate_alts == "" ):
                        alt_item = re.search("\w+:\d+", str(alt_item)).group()
                        mate_alts = "(BND{count}: {alt_item})".format(alt_item=alt_item, count=break_end_count)
                    else:
                        mate_alts = "{mate_alts};(BND{count}: {alt_item})".format(mate_alts=mate_alts, alt_item=alt_item, count=break_end_count)

            ##Merge all mate alts with original bnd alt record
            alt = "{original_entry};{mate_alts}".format(original_entry=alt, mate_alts=mate_alts)

            # Collect format LABELS (PR & SR) for mates (expected to be redundant)
            #=====================================================================
            mate_info_dict["FORMAT"] = mate_format_list.append(mate_record.FORMAT)

            # Collect format INFORMATION (PR & SR) for mates (expected to be redundant)
            #==========================================================================
            read_info_dict, keep_variant_frac_SR_support= collect_read_information_from_event(mate_record)

            if( read_info_dict['TSR'] != "" ):
                sample_tumour_format = "{original_entry};(BND{count}: {PR};{SR})".format(PR=read_info_dict['TPR'], SR=read_info_dict['TSR'], count=break_end_count, original_entry=sample_tumour_format)
            else:
                sample_tumour_format = "{original_entry};(BND{count}: {PR})".format(PR=read_info_dict['TPR'], count=break_end_count, original_entry=sample_tumour_format)

            if( len(record.samples) > 1):
                if( read_info_dict['GSR'] != "" ):
                    sample_germline_format = "{original_entry};(BND{count}: {PR};{SR})".format(PR=read_info_dict['GPR'],SR=read_info_dict['GSR'], count=break_end_count, original_entry=sample_germline_format)
                else:
                    sample_germline_format = "{original_entry};(BND{count}: {PR})".format(PR=read_info_dict['GPR'], count=break_end_count, original_entry=sample_germline_format)
            else:
                sample_germline_format = None


        ##Store event summarise data in list
        v_line2list = [chrom, start, end, sv_type, ref, alt, gene, sv_format, sample_germline_format, sample_tumour_format, location, NM, ACMG, AnnotSV_ID, AnnotSV_ranking, SV_length, keep_variant]

        if(sv_id not in sv_vcf_dict):
            sv_vcf_dict[sv_id] = v_line2list
        else:
            print("ERROR: Key already exists. Dictionary id {sv_id} must be unique for SV of type BND".format(sv_id=sv_id))

    result = [sv_vcf_dict, all_bnd_dict]
    return(result)

def collect_read_information_from_event(record, fraction_SR_support_filter = None):

    #Instantiate variables
    read_info_dict = {}
    sample_germline_format_PR = ""
    sample_germline_format_SR = ""
    sample_tumour_format_PR = ""
    sample_tumour_format_SR = ""
    keep_variant_frac_SR_support_alt = True
    split_read_info_list = []

    #SV labels Manta
    inversion = "INV"
    insertion = "INS"

    sv_id = record.ID
    sv_type = record.INFO["SVTYPE"]

    ## Collect PR and SR information
    #================================
    #Paired analysis
    if(len(record.samples) > 1):

        if(len(record.samples) > 2 or len(record.samples) == 0):
            print("DEBUG UNEXPECTED EVENT OCCURED IN BNDS: SV id {sv_id}".format(sv_id=sv_id))

        #Extract PR reads germline & Tumour
        try:
            sample_germline_format_PR = str(record.samples[0].data.PR).replace("[","").replace("]","")
        except AttributeError:
            sample_germline_format_PR = ""
            print("WARNING: No paired reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

        try:
            sample_tumour_format_PR = str(record.samples[1].data.PR).replace("[","").replace("]","")
        except AttributeError:
            sample_tumour_format_PR = ""
            print("WARNING: No paired reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

        #Extract SR reads germline & tumour
        try:
            sample_germline_format_SR = str(record.samples[0].data.SR).replace("[","").replace("]","")
        except AttributeError:
            sample_germline_format_SR = ""
            print("WARNING: No split reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

        try:
            split_read_info_list = record.samples[1].data.SR
            sample_tumour_format_SR = str(split_read_info_list).replace("[","").replace("]","")
        except AttributeError:
            sample_tumour_format_SR = ""
            print("WARNING: No split reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

    #T-only analysis performed
    elif(len(record.samples) == 1):
        #Extract PR reads tumour
        try:
            sample_tumour_format_PR = str(record.samples[0].data.PR).replace("[","").replace("]","")
        except AttributeError:
            sample_tumour_format_PR = ""
            print("Warning No paired reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

        #Extract SR reads tumour
        try:
            split_read_info_list = record.samples[0].data.SR
            sample_tumour_format_SR = str(split_read_info_list).replace("[","").replace("]","")
        except AttributeError:
            sample_tumour_format_SR = ""
            print("Warning No paired reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

    read_info_dict = {
        "GPR": sample_germline_format_PR.replace(" ", ""),
        "GSR": sample_germline_format_SR.replace(" ", ""),
        "TPR": sample_tumour_format_PR.replace(" ", ""),
        "TSR": sample_tumour_format_SR.replace(" ", "")
    }

    if( split_read_info_list != [] ):
        if(sv_type == insertion or sv_type == inversion):
            SR_ref = split_read_info_list[0]
            SR_alt = split_read_info_list[1]
            
            #Avoid zero division 
            if( (SR_ref + SR_alt) == 0 ):
                frac_SR_support_alt = 0
            else:
                frac_SR_support_alt = SR_alt/(SR_ref + SR_alt)                

            if(frac_SR_support_alt < fraction_SR_support_filter):
                keep_variant_frac_SR_support_alt = False

    return(read_info_dict, keep_variant_frac_SR_support_alt)

def collect_read_information_from_smallindel_event(record, end):

    #Instantiate variables
    read_info_dict = {}
    sample_germline_format_TIR = ""
    sample_tumour_format_TIR = ""

    ###########
    ## NOTE! ##
    ###########
    # First value (TIER1 filtered value) of TIR (alt read support) taken
    # which means multi alleic sites (depending on how TIR is reported) will
    # incorrectly select the wrong nr of read support as it will always take first value of TIR.

    indel_id = "{c}:{s}:{e}:{ref}".format(c=record.CHROM, s=record.POS, e=end, ref=record.REF)

    ## Collect TIR (alt reads supporting indel)
    #===========================================
    if(len(record.samples) > 1):

        if(len(record.samples) > 2 or len(record.samples) == 0):
            print("DEBUG UNEXPECTED EVENT OCCURED IN SMALL INDEL: INDEL id {indel_id}".format(indel_id=indel_id))

        #Extract TIR reads germline & Tumour
        try:
            sample_germline_format_TIR = str(record.samples[0].data.TIR[0])
        except AttributeError:
            sample_germline_format_TIR = ""
            print("WARNING: No ALT (TIR) reads for Indel ID {indel_id}".format(indel_id=indel_id))

        try:
            sample_tumour_format_TIR = str(record.samples[1].data.TIR[0])
        except AttributeError:
            sample_tumour_format_TIR = ""
            print("WARNING: No ALT (TIR) reads for Indel ID {indel_id}".format(indel_id=indel_id))


    #T-only analysis performed
    elif(len(record.samples) == 1):
        #Extract TIR reads tumour
        try:
            sample_tumour_format_TIR = str(record.samples[0].data.TIR[0])
        except AttributeError:
            sample_tumour_format_TIR = ""
            print("Warning No ALT (TIR) reads for Indel ID {indel_id}".format(indel_id=indel_id))

    read_info_dict = {
        "GTIR": sample_germline_format_TIR,
        "TTIR": sample_tumour_format_TIR,
    }

    return(read_info_dict)

#Fetch coverage
def fetch_coverage(bam, chrom, start, stop_list, indel_type):

    DP_list = []
    samfile = pysam.AlignmentFile(bam, "rb")

    #Indel labels
    deletion = "DEL"
    insertion = "INS"
    del_insertion = "DELINS"

    #For deletions calcualate DP by taking median coverage before and after deletion and take average
    for stop in stop_list:
        padding = 10

        if(indel_type == deletion):
            cov_per_base_pre = samfile.count_coverage(chrom, start - padding, start)

            cov_per_base_post = samfile.count_coverage(chrom, stop, stop + padding)

            cov_per_base_sum_pre = np.array(cov_per_base_pre[0]) + np.array(cov_per_base_pre[1]) + np.array(cov_per_base_pre[2]) + np.array(cov_per_base_pre[3])

            cov_per_base_sum_post = np.array(cov_per_base_post[0]) + np.array(cov_per_base_post[1]) + np.array(cov_per_base_post[2]) + np.array(cov_per_base_post[3])

            median_cov_pre = np.median(cov_per_base_sum_pre)
            median_cov_post = np.median(cov_per_base_sum_post)
            mean_cov = np.mean( np.array( [median_cov_pre, median_cov_post] ) )

            DP_list.append(int(mean_cov))

        else:
            cov_per_base = samfile.count_coverage(chrom, start, stop)
            cov_per_base_sum = np.array(cov_per_base[0]) + np.array(cov_per_base[1]) + np.array(cov_per_base[2]) + np.array(cov_per_base[3])
            median_cov = np.median(cov_per_base_sum)

            DP_list.append(int(median_cov))

    return(DP_list)

def find_full_event(sv_vcf_dict, sv_record_dict_by_type):

    full_event_found = []
    sv_ids_to_delete = []
    breakend_label = "BND"
    inversion_label = "INV"


    for sv_id, tsv_line in sv_vcf_dict.items():

        if(sv_id in sv_record_dict_by_type):
            sv_type = tsv_line[3]

            if(sv_type == breakend_label):
                record = sv_record_dict_by_type[sv_id][0]
            elif(sv_type == inversion_label):
                record = sv_record_dict_by_type[sv_id]
        else:
            continue

        sv_type = record.INFO['SVTYPE']

        if( sv_type == breakend_label or sv_type == inversion_label):
            try:
                event_id = record.INFO['EVENT']
                if(event_id in full_event_found):
                    continue
                else:
                    full_event_found.append(event_id)
                    bnd_pair1_tsv_line = tsv_line

                    for sv_id_nested_lp, tsv_line_nested_lp in sv_vcf_dict.items():
                        record_nested_lp = sv_record_dict_by_type[sv_id_nested_lp]

                        try:
                            event_id_nested_lp = record_nested_lp.INFO['EVENT']

                            if( event_id_nested_lp == event_id and sv_id != sv_id_nested_lp):
                                sv_ids_to_delete.append(sv_id_nested_lp)

                                #Merge BND into full event
                                if(sv_type == breakend_label):
                                    print("INFO: Full EVENT found for BND EVENT {event_id}".format(event_id=event_id))
                                    sv_vcf_dict = merge_full_event_of_type_bnd(sv_vcf_dict, sv_id, tsv_line, tsv_line_nested_lp)

                                if(sv_type == inversion_label):
                                    print("INFO: Full EVENT found for INV EVENT {event_id}".format(event_id=event_id))
                                    sv_vcf_dict = merge_full_event_of_type_inv(sv_vcf_dict, sv_record_dict_by_type, sv_id, sv_id_nested_lp, tsv_line, tsv_line_nested_lp)

                        except KeyError:
                            continue
            except KeyError:
                continue

    #Delete SV ids that are redundant from dict
    for sv_id_to_del in sv_ids_to_delete:
        del sv_vcf_dict[sv_id_to_del]

    return(sv_vcf_dict)

##Merges separate BND events into one event
def merge_full_event_of_type_bnd(sv_vcf_dict, sv_id, tsv_line_pair1, tsv_line_pair2):

    #Indexes for results to be modified (future proof by using dictionary instead for v_line2list)
    #merge alt index 5
    #merge germline read info 8
    #merge tumour read info 9
    #logical filter 16

    keep_variant_p1 = tsv_line_pair1[16]
    keep_variant_p2 = tsv_line_pair2[16]

    if(keep_variant_p1 or keep_variant_p2):
        keep_variant = True
    else:
        keep_variant = False

    merged_alt_record = "{pair1_alt}{pair2_alt}".format(pair1_alt=tsv_line_pair1[5], pair2_alt=tsv_line_pair2[5])
    merged_germline_read_info = "{pair1_gread};{pair2_gread}".format(pair1_gread=tsv_line_pair1[8], pair2_gread=tsv_line_pair2[8])
    merged_tumour_read_info = "{pair1_tread};{pair2_tread}".format(pair1_tread=tsv_line_pair1[9], pair2_tread=tsv_line_pair2[9])

    new_tsv_line = tsv_line_pair1
    new_tsv_line[5] = merged_alt_record
    new_tsv_line[8] = merged_germline_read_info
    new_tsv_line[9] = merged_tumour_read_info
    new_tsv_line[16] = keep_variant
    sv_vcf_dict[sv_id] = new_tsv_line

    return(sv_vcf_dict)

##Merges separate BND events into one event
def merge_full_event_of_type_inv(sv_vcf_dict, inv_dict, sv_id, sv_id_event_pair, tsv_line_pair1, tsv_line_pair2):

    #Indexes for results to be modified (future proof by using dictionary instead for v_line2list)
    #merge alt index 5
    #merge germline read info 8
    #merge tumour read info 9
    #logical filter 16

    inversion_label = "INV"
    inv_3_prime = "INV3"
    inv_5_prime = "INV5"
    merged_alt_record = ""

    keep_variant_p1 = tsv_line_pair1[16]
    keep_variant_p2 = tsv_line_pair2[16]

    if(keep_variant_p1 or keep_variant_p2):
        keep_variant = True
    else:
        keep_variant = False

    # Extract if inversion is INV3 or INV5
    #=====================================
    try:
        if(inv_dict[sv_id].INFO[inv_3_prime]):
            inv_type = inv_3_prime

        sv_id_pair1_inv3 = "{inv_type}:{chrom_p1}:{s_p1}-{e_p1}".format(inv_type=inv_type, chrom_p1=tsv_line_pair1[0], s_p1=tsv_line_pair1[1], e_p1=tsv_line_pair1[2])
    except KeyError:
        sv_id_pair1_inv3 = None

    try:
        if(inv_dict[sv_id].INFO[inv_5_prime]):
            inv_type = inv_5_prime

        sv_id_pair1_inv5 = "{inv_type}:{chrom_p1}:{s_p1}-{e_p1}".format(inv_type=inv_type, chrom_p1=tsv_line_pair1[0], s_p1=tsv_line_pair1[1], e_p1=tsv_line_pair1[2])
    except KeyError:
        sv_id_pair1_inv5 = None

    try:
        if(inv_dict[sv_id_event_pair].INFO[inv_3_prime]):
            inv_type = inv_3_prime

        sv_id_pair2_inv3 = "{inv_type}:{chrom_p2}:{s_p2}-{e_p2}".format(inv_type=inv_type, chrom_p2=tsv_line_pair2[0], s_p2=tsv_line_pair2[1], e_p2=tsv_line_pair2[2])
    except KeyError:
        sv_id_pair2_inv3 = None

    try:
        if(inv_dict[sv_id_event_pair].INFO[inv_5_prime]):
            inv_type = inv_5_prime

        sv_id_pair2_inv5 = "{inv_type}:{chrom_p2}:{s_p2}-{e_p2}".format(inv_type=inv_type, chrom_p2=tsv_line_pair2[0], s_p2=tsv_line_pair2[1], e_p2=tsv_line_pair2[2])
    except KeyError:
        sv_id_pair2_inv5 = None


    # Overwite ALT tag with INV3 and INV5 info
    #==========================================
    if(sv_id_pair1_inv3 and sv_id_pair2_inv5):
        merged_alt_record = "({inv5});({inv3})".format(inv5=sv_id_pair2_inv5, inv3=sv_id_pair1_inv3)
    elif(sv_id_pair1_inv5 and sv_id_pair2_inv3):
        merged_alt_record = "({inv5});({inv3})".format(inv5=sv_id_pair1_inv5, inv3=sv_id_pair2_inv3)

    merged_germline_read_info = "{pair1_gread};{pair2_gread}".format(pair1_gread=tsv_line_pair1[8], pair2_gread=tsv_line_pair2[8])
    merged_tumour_read_info = "{pair1_tread};{pair2_tread}".format(pair1_tread=tsv_line_pair1[9], pair2_tread=tsv_line_pair2[9])
    new_tsv_line = tsv_line_pair1
    new_tsv_line[5] = merged_alt_record
    new_tsv_line[8] = merged_germline_read_info
    new_tsv_line[9] = merged_tumour_read_info
    new_tsv_line[16] = keep_variant
    sv_vcf_dict[sv_id] = new_tsv_line

    return(sv_vcf_dict)

def filter_PR(supporting_reads_int, sv_type, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter):

    keep_variant = False

    #SV labels Manta
    breakend = "BND"
    inversion = "INV"
    insertion = "INS"
    deletion = "DEL"
    tandem_duplication = "DUP"

    if(sv_type == breakend):
        if(supporting_reads_int >= bnd_PR_filter):
            keep_variant = True

    if(sv_type == inversion):
        if(supporting_reads_int >= inv_PR_filter):
            keep_variant = True

    if(sv_type == insertion):
        if(supporting_reads_int >= ins_PR_filter):
            keep_variant = True

    if(sv_type == deletion):
        if(supporting_reads_int >= del_PR_filter):
            keep_variant = True

    if(sv_type == tandem_duplication):
        if(supporting_reads_int >= dup_PR_filter):
            keep_variant = True

    return(keep_variant)

def filter_SR(supporting_reads_int, sv_type, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter):

    keep_variant = False

    #SV labels Manta
    breakend = "BND"
    inversion = "INV"
    insertion = "INS"
    deletion = "DEL"
    tandem_duplication = "DUP"


    if(sv_type == breakend):
        if(supporting_reads_int >= bnd_SR_filter):
            keep_variant = True

    if(sv_type == inversion):
        if(supporting_reads_int >= inv_SR_filter):
            keep_variant = True

    if(sv_type == insertion):
        if(supporting_reads_int >= ins_SR_filter):
            keep_variant = True

    if(sv_type == deletion):
        if(supporting_reads_int >= del_SR_filter):
            keep_variant = True

    if(sv_type == tandem_duplication):
        if(supporting_reads_int >= dup_SR_filter):
            keep_variant = True

    return(keep_variant)

#Checks if variant should be filtered and returns boolean
def check_filter_variant(record, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter):
    sv_id = record.ID
    sv_type = record.INFO['SVTYPE']

    keep_variant_PR_bol = None
    keep_variant_SR_bol = None
    keep_variant = False

    ## Collect PR and SR information
    #================================
    #Paired analysis
    if(len(record.samples) > 1):

        if(len(record.samples) > 2 or len(record.samples) == 0):
            print("DEBUG UNEXPECTED EVENT OCCURED IN variant_filter: SV id {sv_id}".format(sv_id=sv_id))

        try:
            sample_tumour_PR_int = record.samples[1].data.PR[1]
            keep_variant_PR_bol = filter_PR(sample_tumour_PR_int, sv_type, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter)

        except AttributeError:
            print("WARNING: No paired reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

        try:
            sample_tumour_SR_int = record.samples[1].data.SR[1]
            keep_variant_SR_bol = filter_SR(sample_tumour_SR_int, sv_type, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter)

        except AttributeError:
            #keep_variant_SR_bol = None
            print("WARNING: No split reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

    #T-only analysis performed
    elif(len(record.samples) == 1):
        #Extract PR reads tumour
        try:
            sample_tumour_PR_int = record.samples[0].data.PR[1]
            keep_variant_PR_bol = filter_PR(sample_tumour_PR_int, sv_type, bnd_PR_filter, inv_PR_filter, dup_PR_filter, ins_PR_filter, del_PR_filter)

        except AttributeError:
            print("Warning No paired reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

        #Extract SR reads tumour
        try:
            sample_tumour_SR_int = record.samples[0].data.SR[1]
            keep_variant_SR_bol = filter_SR(sample_tumour_SR_int, sv_type, bnd_SR_filter, inv_SR_filter, dup_SR_filter, ins_SR_filter, del_SR_filter)

        except AttributeError:
            #sample_tumour_SR_int = None
            print("Warning No paired reads for SV with EVENT ID {sv_id}".format(sv_id=sv_id))

    #Filter variant if either PR or SR fails the criteria if PR and SR both present
    if(not keep_variant_SR_bol == None):
        if(keep_variant_PR_bol or keep_variant_SR_bol):
            keep_variant = True
        else:
            keep_variant = False
    else:
        if(keep_variant_PR_bol):
            keep_variant = True

    return(keep_variant)

##Variants tagged to be filtered are removed from final output
def exclude_filtered_var_from_dict(sv_vcf_dict):

    #Logical variant filter index 16
    sv_vcf_dict_copy = sv_vcf_dict.copy()
    for sv_id, tsv_line in sv_vcf_dict.items():
        keep_variant = tsv_line[16]

        if(not keep_variant):
            del sv_vcf_dict_copy[sv_id]
        else:
            #Remove logical from final output
            new_tsv_line = tsv_line[0:(len(tsv_line) - 1)]
            sv_vcf_dict_copy[sv_id] = new_tsv_line

    return(sv_vcf_dict_copy)

#Scans genome in specified region for RR read support. RR and LL read support are indicative of inversion.
def filter_inv_on_pair_orientation(sv_vcf_dict, inv_dict, bam, inv_PO_filter, padding=150):

    ##Instantiate variables & labels
    sv_vcf_dict_copy = sv_vcf_dict.copy()
    RR_support_dict = {}
    inversion = "INV"
    function_name = "filter_inv_on_pair_orientation"

    #Scan reads support for each sv_id record
    #=========================================
    for sv_id, tsv_line in sv_vcf_dict.items():
        keep_variant = True
        if(sv_id in inv_dict):
            record = inv_dict[sv_id]
            sv_type = record.INFO['SVTYPE']

            if(sv_type == inversion):

                #Set variables
                chrom = record.CHROM
                start = record.POS - padding
                end = record.sv_end + padding
                region = "{c}:{s}-{e}".format(c=chrom, s=start, e=end)
                flags="113,177"

                #Fetch read likely RR read support
                my_read_list = re.split("\n", pysam.view("-f", flags, bam, region))
                RR_read_support = len(my_read_list)

                print("\nMESSAGE: {tsv_line} RR READ SUPPORT {RR_read_support}\n".format(tsv_line=str(tsv_line), RR_read_support=RR_read_support))

                #Remove effect of trailing new line
                if("" in my_read_list):
                    my_read_list.pop()

                if( RR_read_support < inv_PO_filter ):
                    keep_variant = False

                if(sv_id not in RR_support_dict):
                    RR_support_dict[sv_id] = [keep_variant, RR_read_support]
                else:
                    print("ERROR: A duplicate sv_id was found in function {function_name} for ID {sv_id}".format(function_name=function_name, sv_id=sv_id))

    # Filter SVs with lacking RR read support
    #=========================================
    for sv_id, RR_support_list in RR_support_dict.items():
        keep_variant = RR_support_list[0]
        RR_read_support = RR_support_list[1]

        if(not keep_variant):
            del sv_vcf_dict_copy[sv_id]
            print("MESSAGE: Inversion filtered due to lack of RR read support for {sv_id}. Number of RR reads detected {RR_support}. Variant is excluded from final output\n".format(sv_id=sv_id, RR_support=RR_read_support))
        continue

    return(sv_vcf_dict_copy)


#Read & store AnnotSV file as dictionary
def annotSV2dict(annotsv):

    #Column 11 i.e. index 10 AnnotSV type [full|split]

    header = True
    header_list = []
    annotSVdict = {}
    annotSVdict_nested = {}
    with open(annotsv, "r") as annot_IN:
        for line in annot_IN:
            line = line.strip()
            match = re.split("\t", line)
            compartmentalised = match[10]

            ##Store header in dict
            if(header):
                for i in range(0, len(match)):
                    header_list.append(match[i])
                header = False
                continue

            ##Load data to dict
            if(compartmentalised == "full"):
                key = "{chrom}:{start}:{end}:{sv_type}".format(chrom=match[1], start=match[2], end=match[3], sv_type=match[5])

                if(key not in annotSVdict):
                    for i in range(0, len(match)):
                        if(header_list[i] not in annotSVdict_nested):
                            annotSVdict_nested[header_list[i]] = match[i]
                        else:
                            print("ERROR: Duplicate header found in annotSV")

                    annotSVdict[key] = annotSVdict_nested
                    annotSVdict_nested = {}
                else:
                    print("WARNING: Structural with key {sv_key} appears >=2 in AnnotSV".format(sv_key=key))

    return(annotSVdict)

#Read & store genes on panel as list
def bed2gene_list(bedfile):

    header = True
    gene_list = []
    with open(bedfile, "r") as bedfile_IN:
        for line in bedfile_IN:

            #Skip reading genome dictionary
            if(line.startswith("@")):
                continue

            line = line.strip()
            match = re.split("\t", line)
            gene_name = re.split("_", match[4])[0]

            if( gene_name not in gene_list ):
                gene_list.append(gene_name)
    return(gene_list)


#Join annotSV data with sv vcf dict (so far only SV rank)
def join_annotSV(sv_vcf_dict, annotSVdict):
    sv_vcf_dict_copy = sv_vcf_dict.copy()

    #SV labels Manta
    breakend = "BND"
    insertion = "INS"

    for manta_key, tsv_line in sv_vcf_dict.items():
        start = tsv_line[1]
        end = tsv_line[2]
        sv_type = tsv_line[3]

        #1bp location stored as start=1 and stop=2. BNDs reported as 1bp locations
        # and due to bug insertions as well so the stop needs to be adjusted for insertions)
        if(sv_type == breakend or sv_type == insertion):
            end = int(start) + 1

        key = "{chrom}:{start}:{end}:{sv_type}".format(chrom=tsv_line[0].replace("chr", ""), start=start, end=end, sv_type=sv_type)
        if(key in annotSVdict):
            new_tsv_line = tsv_line
            new_tsv_line[14] = annotSVdict[key]['AnnotSV ranking']
            sv_vcf_dict_copy[manta_key] = new_tsv_line
        else:
            print("WARNING: Record {key} in manta doesn't exist in AnnotSV output. Either there is an error in AnnotSV or no AnnotSV database record exist".format(key=key))

    return(sv_vcf_dict_copy)

def filter_blacklisted_bnds(sv_vcf_dict, blacklist_bnd_genes_dict):
    sv_vcf_dict_copy = sv_vcf_dict.copy()

    #SV labels Manta
    breakend = "BND"

    for sv_id, tsv_line in sv_vcf_dict.items():
        if(tsv_line[3] == breakend):
            genes = re.split("-", tsv_line[10])
            for gene in genes:
                if(gene in blacklist_bnd_genes_dict):
                    del sv_vcf_dict_copy[sv_id]

    return(sv_vcf_dict_copy)

##Convert to tsv line
def string2tsv_line(my_tuple):
    tsv_line = ""
    for item in my_tuple:
        tsv_line = tsv_line + str(item) + "\t"
    tsv_line = tsv_line + "\n"
    return(tsv_line)

#Store ratios in bed file
def write_dict2report(sv_vcf_dict, output_file, suffix):
    header = True
    header_tuple = ["#SV_chrom", "SV_start", "SV_end", "SV_type", "REF", "ALT", "Gene_name", "FORMAT", "Germline", "Tumour", "location", "NM", "ACMG", "AnnotSV_ID", "AnnotSV_ranking", "SV_length"]
    output_file = output_file + suffix

    with open(output_file, "w") as report_OUT:
        for key, sv_tuple in sv_vcf_dict.items():

            #Write header
            if(header):
                report_OUT.write(string2tsv_line(header_tuple))
                header = False

            report_OUT.write(string2tsv_line(sv_tuple))

def main(argv):

    nr_arguments = 4 #Total number of arguments 21

    #Stores flags with arguments in opts (both flag in and input stored) and flags with no input in args
    try:
        opts, args = getopt.getopt(argv, "mvcf:pvcf:o:b:n:i:amanta:apindel:l:findel:fbndpr:fbndsr:finvpr:finvsr:fduppr:fdupsr:finspr:finssr:fdelpr:fdelsr:finvpo:frctionsr:h", ["manta_vcf=", "pindel_vcf=", "output_file=", "bam=", "nr_bases2preview=", "small_indel_vcf=", "annotSV_file_manta=", "annotSV_file_pindel=", "bed_interval_file=", "indel_allele_frac_filter=", "BND_pair_read_filter=", "BND_split_read_filter=", "INV_pair_read_filter=", "INV_split_read_filter=", "DUP_pair_read_filter=", "DUP_split_read_filter=", "INS_pair_read_filter=", "INS_split_read_filter=", "DEL_pair_read_filter=", "DEL_split_read_filter=","inv_PO_read_filter=", "fraction_SR_support_alt=", "help="])
    except getopt.GetoptError: # If no argument given
        write_script_usage()
        sys.exit(2)
    #Loop through flags (opt) and arguments (arg) from opts. Store appropriately
    for opt, arg in opts:
        if opt in ("-h", "--help"):
            write_script_usage()
            sys.exit(2)
        elif opt in ("-mvcf", "--manta_vcf"):
            manta_vcf = arg
        elif opt in ("-pvcf", "--pindel_vcf"):
            pindel_vcf = arg
        elif opt in ("-o", "--output_file"):
            output_file = arg
        elif opt in ("-b", "--bam"):
            bam = arg
        elif opt in ("-n", "--nr_bases2preview"):
            nr_bases2preview = int(arg)
        elif opt in ("-i", "--small_indel_vcf"):
            small_indel_vcf = arg
        elif opt in ("-amanta", "--annotSV_file_manta"):
            annotSV_file_manta = arg
        elif opt in ("-apindel", "--annotSV_file_pindel"):
            annotSV_file_pindel = arg
        elif opt in ("-l", "--bed_interval_file"):
            bed_interval_file = arg
        elif opt in ("-findel", "--indel_allele_frac_filter"):
            indel_allele_frac_filter = float(arg)
        elif opt in ("-fbndpr", "--BND_pair_read_filter"):
            if(arg == "false"):
                BND_pair_read_filter = arg
            else:
                BND_pair_read_filter = int(arg)
        elif opt in ("-fbndsr", "--BND_split_read_filter"):
            if(arg == "false"):
                BND_split_read_filter = arg
            else:
                BND_split_read_filter = int(arg)
        elif opt in ("-finvpr", "--INV_pair_read_filter"):
            if(arg == "false"):
                INV_pair_read_filter = arg
            else:
                INV_pair_read_filter = int(arg)
        elif opt in ("-finvsr", "--INV_split_read_filter"):
            if(arg == "false"):
                INV_split_read_filter = arg
            else:
                INV_split_read_filter = int(arg)
        elif opt in ("-fduppr", "--DUP_pair_read_filter"):
            if(arg == "false"):
                DUP_pair_read_filter = arg
            else:
                DUP_pair_read_filter = int(arg)
        elif opt in ("-fdupsr", "--DUP_split_read_filter"):
            if(arg == "false"):
                DUP_split_read_filter = arg
            else:
                DUP_split_read_filter = int(arg)
        elif opt in ("-finspr", "--INS_pair_read_filter"):
            if(arg == "false"):
                INS_pair_read_filter = arg
            else:
                INS_pair_read_filter = int(arg)
        elif opt in ("-finssr", "--INS_split_read_filter"):
            if(arg == "false"):
                INS_split_read_filter = arg
            else:
                INS_split_read_filter = int(arg)
        elif opt in ("-fdelpr", "--DEL_pair_read_filter"):
            if(arg == "false"):
                DEL_pair_read_filter = arg
            else:
                DEL_pair_read_filter = int(arg)
        elif opt in ("-fdelsr", "--DEL_split_read_filter"):
            if(arg == "false"):
                DEL_split_read_filter = arg
            else:
                DEL_split_read_filter = int(arg)
        elif opt in ("-finvpo", "--inv_PO_read_filter"):
            inv_PO_read_filter = int(arg)
        elif opt in ("-frctionsr", "--fraction_SR_support_alt"):
            fraction_SR_support_alt = float(arg)


    #If only in or out given print usage and error
    if len(argv)/2 < nr_arguments:
        print("You submitted " + str(int(len(argv)/2)) + " arguments, expected " + str(nr_arguments))
        print('not enough arguments.... see below for run usage:')
        write_script_usage()
        sys.exit(2)

    #Logicals to run script independantly
    try:
        if(manta_vcf):
            create_manta_report = True
    except UnboundLocalError:
        create_manta_report = False

    try:
        if(pindel_vcf):
            create_pindel_report = True
    except UnboundLocalError:
        create_pindel_report = False


    #Create report manta
    if(create_manta_report):
        manta_sv_vcf_dict, small_indel_dict = SV_vcf2dict_MANTA(manta_vcf, small_indel_vcf, bam, annotSV_file_manta, bed_interval_file,  nr_bases2preview, indel_allele_frac_filter, BND_pair_read_filter, BND_split_read_filter, INV_pair_read_filter, INV_split_read_filter, DUP_pair_read_filter, DUP_split_read_filter, INS_pair_read_filter, INS_split_read_filter, DEL_pair_read_filter, DEL_split_read_filter,inv_PO_read_filter, fraction_SR_support_alt)

        write_dict2report(manta_sv_vcf_dict, output_file, ".SV.vcf.report")
        write_dict2report(small_indel_dict, output_file, ".SmallIndel.vcf.report")

    #Create report pindel
    if(create_pindel_report):
        pindel_sv_vcf_dict = SV_vcf2dict_PINDEL(pindel_vcf, nr_bases2preview)
        write_dict2report(pindel_sv_vcf_dict, output_file, ".Pindel_SV.vcf.report")

if __name__ == "__main__":
    main(sys.argv[1:])
